FROM pytorch/pytorch:2.9.0-cuda12.6-cudnn9-runtime AS pytorch-2.9.0-base
FROM pytorch-2.9.0-base AS pytorch-2.9.0-test

RUN apt-get install -y --no-install-recommends git build-essential cmake ninja-build 

RUN rm -rf /var/lib/apt/lists/*

RUN pip install -U pip setuptools wheel

# Option A: simplest (if vLLM wheels resolve cleanly for your platform)
RUN pip install vllm


# Set environment variables
ENV DEBIAN_FRONTEND=noninteractive
ENV CUDA_HOME=/usr/local/cuda
ENV PATH=${CUDA_HOME}/bin:${PATH}
ENV LD_LIBRARY_PATH=${CUDA_HOME}/lib64:${LD_LIBRARY_PATH}


# Install Python dependencies required for profiling
RUN pip install --no-cache-dir \
    pandas \
    scipy \
    ray[default] \
    wandb \
    kaleido \
    plotly \
    seaborn \
    matplotlib \
    fasteners \
    pyyaml \
    tqdm \
    packaging \
    setuptools \
    wheel

WORKDIR /workspace

# Clone Sarathi-Serve
RUN git clone --branch vidur https://github.com/microsoft/sarathi-serve.git

WORKDIR /workspace/sarathi-serve

# Install Sarathi-Serve with robust CUDA_HOME detection
# 1. We look for the directory starting with cuda- in /usr/local (e.g., cuda-12.3)
# 2. We export that as CUDA_HOME
# 3. We add it to PATH
# 4. We run pip install
# RUN export CUDA_HOME=$(ls -d /usr/local/cuda-* | head -n 1) && \
#     echo "Detected CUDA_HOME as: $CUDA_HOME" && \
#     if [ -z "$CUDA_HOME" ]; then echo "Error: Could not find CUDA directory in /usr/local"; exit 1; fi && \
#     export PATH=$CUDA_HOME/bin:$PATH && \
#     export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH && \
#     # Verify nvcc exists there
#     if [ ! -f "$CUDA_HOME/bin/nvcc" ]; then echo "Error: nvcc not found at $CUDA_HOME/bin/nvcc"; exit 1; fi && \
#     echo "nvcc found at: $($CUDA_HOME/bin/nvcc --version)" && \
    # Install with --no-build-isolation to use system torch
FROM pytorch-2.9.0-base AS vidur-profiling

RUN pip install --no-build-isolation -v .

WORKDIR /app
ENV PYTHONPATH="${PYTHONPATH}:/app"

CMD ["/bin/bash"]
